{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cecd07a-c1f8-47e7-97cb-6b2358f17465",
   "metadata": {},
   "source": [
    "# convolver.ipynb\n",
    "\n",
    "Convolve input images from the robot with a given filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69fb7c-3981-46b6-8e89-9e82192f86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#import matplotlib.animation as animation\n",
    "#from IPython.display import HTML\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils import data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1742fc63-07df-4991-9eb0-fd098237a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# 64x64\n",
    "#path = \"/mnt/bucket/TaniU/Members/prasanna/dataset_5x8/5x6comp1train_dataset0901.h5\"\n",
    "# 256x256\n",
    "path = \"/mnt/bucket/TaniU/Members/prasanna/prasanna_data/datasets/groupA1_traindataset_256x256.h5\"\n",
    "#path = \"/mn/bucket/TaniU/Members/prasanna/prasanna_data/datasets/groupA1_testdataset_256x256.h5\"\n",
    "\n",
    "# quick information\n",
    "f = h5py.File(path, 'r')\n",
    "keys = list(f.keys())\n",
    "for key in keys:\n",
    "    print(f\"'{key}' \\t dataset shape: {f[key].shape}\")\n",
    "\n",
    "# dataset class\n",
    "class JaxDataset(data.Dataset):\n",
    "    \"\"\" A Torch Dataset class with the HDF5 datasets.\n",
    "\n",
    "    :param data_path: path of the HDF5 dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        f = h5py.File(data_path, 'r')\n",
    "        self.lang_mask = f['lang_mask']\n",
    "        self.language = f['language']\n",
    "        self.mask = f['mask']\n",
    "        self.motor = f['motor']\n",
    "        self.vision = f['vision']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vision.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Returns the training data corresponding to 'index'.\n",
    "\n",
    "        :param index: index of the data to return\n",
    "        :type index: int\n",
    "        :return: vision, motor, language, mask, lang_mask\n",
    "        :rtype: tuple(JAX array)\n",
    "        \"\"\"\n",
    "        return (self.vision[index], self.motor[index], self.language[index],\n",
    "                self.mask[index], self.lang_mask[index])\n",
    "\n",
    "dataset = JaxDataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261c839-55c3-4f16-a15f-7dd17de5466f",
   "metadata": {},
   "source": [
    "---\n",
    "The next cell sets the images in the example in a grid. This code comes from\n",
    "the Pytorch [visualization utilities](https://pytorch.org/vision/stable/auto_examples/plot_visualization_utils.html#sphx-glr-auto-examples-plot-visualization-utils-py) documentation.\n",
    "\n",
    "It is assumed that vision has index 0, and visual data has\n",
    "shape `[N, 3, W, H]`, i.e. N RGB images of size WxH.  \n",
    "Moreover, those images have data in the range [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05da18-3328-4f05-b0cc-433954356785",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 12\n",
    "example = dataset[example_index]\n",
    "vision = example[0]\n",
    "print(f\"For index {example_index}, the vision data has shape {vision.shape}\")\n",
    "\n",
    "imgs = vision / 2. + 0.5\n",
    "grid = make_grid(torch.tensor(imgs))\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, figsize=(10,10))\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acfe276-914b-4634-925a-1a65327f6bc5",
   "metadata": {},
   "source": [
    "Let's convolve all the images in the example with a set filter, using `lax.conv_general_dilated` as in [the tutorial](https://jax.readthedocs.io/en/latest/notebooks/convolutions.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b30e56-50c5-41b4-8c6e-e748c080b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D kernel - HWIO layout\n",
    "kernel = jnp.zeros((3, 3, 3, 3), dtype=jnp.float32)\n",
    "# kernel += jnp.array([[1, 1, 0],\n",
    "#                      [1, 0,-1],\n",
    "#                      [0,-1,-1]])[:, :, jnp.newaxis, jnp.newaxis]\n",
    "\n",
    "# kernel += jnp.array([[1,  .5,-1],\n",
    "#                      [1,   0,-1],\n",
    "#                      [1, -.5,-1]])[:, :, jnp.newaxis, jnp.newaxis]\n",
    "\n",
    "kernel += jnp.array([[ 1, -1,  1],\n",
    "                     [-1,  0, -1],\n",
    "                     [ 1, -1,  1]])[:, :, jnp.newaxis, jnp.newaxis]\n",
    "print(\"Conv kernel:\")\n",
    "plt.imshow(kernel[:, :, 0, 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8523d-dc8c-45b6-b1c6-d009b6f8c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = lax.conv_dimension_numbers(vision.shape,     # only ndim matters, not shape\n",
    "                                kernel.shape,  # only ndim matters, not shape \n",
    "                                ('NCHW', 'HWIO', 'NCHW'))  # the important bit\n",
    "print(dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac35724-2024-4f60-86ba-116997434551",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = lax.conv_general_dilated(vision,    # lhs = image tensor\n",
    "                               kernel, # rhs = conv kernel tensor\n",
    "                               (1,1),  # window strides\n",
    "                               'SAME', # padding mode\n",
    "                               (1,1),  # lhs/image dilation\n",
    "                               (1,1),  # rhs/kernel dilation\n",
    "                               dn)     # dimension_numbers = lhs, rhs, out dimension permutation\n",
    "print(\"out shape: \", out.shape)\n",
    "print(\"First output channel:\")\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(np.array(out)[0, 0, :, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1084ba9-d24b-44df-9637-3e1de7fd3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_out = torch.from_numpy(np.asarray(out))  # shouldn't do in real code\n",
    "imgs = pt_out / 2. + 0.5\n",
    "grid = make_grid(torch.tensor(imgs))\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, figsize=(12,12))\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5fc16",
   "metadata": {},
   "source": [
    "---\n",
    "Quick example of implementing transpose convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35652042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import lax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fbcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, the direct convolution\n",
    "\n",
    "in_chan = 256  # number of input channels\n",
    "out_chan = 64  # number of output channels\n",
    "batch_size = 32\n",
    "kernel = jnp.ones((in_chan, out_chan, 3, 3))\n",
    "images = jnp.ones((batch_size, in_chan, 6, 6))\n",
    "\n",
    "dn = lax.conv_dimension_numbers(images.shape,  # Dimensions for the input\n",
    "                                kernel.shape,  # Dimensions of the kernel\n",
    "                                ('NCHW', 'IOHW', 'NCHW'))  # what each dimension is\n",
    "                                                 # in the input, kernel, and output\n",
    "\n",
    "out = lax.conv_general_dilated(images, # lhs = image tensor\n",
    "                               kernel, # rhs = conv kernel tensor\n",
    "                               (1,1),  # window strides\n",
    "                               'VALID', # padding mode\n",
    "                               (1,1),  # lhs/image dilation\n",
    "                               (1,1),  # rhs/kernel dilation\n",
    "                               dn)     # dimension_numbers\n",
    "\n",
    "print(f\"Output shape: {out.shape}\")\n",
    "\n",
    "\n",
    "#help(jax.lax.conv_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81156cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, the corresponding transpose convolution\n",
    "images = jnp.ones((batch_size, in_chan, 4, 4))\n",
    "\n",
    "dn = lax.conv_dimension_numbers(images.shape,  # Dimensions for the input\n",
    "                                kernel.shape,  # Dimensions of the kernel\n",
    "                                ('NCHW', 'IOHW', 'NCHW'))  # what each dimension is\n",
    "                                                 # in the input, kernel, and output\n",
    "\n",
    "out = lax.conv_general_dilated(images, # lhs = image tensor\n",
    "                               kernel, # rhs = conv kernel tensor\n",
    "                               (1,1),  # window strides\n",
    "                               [(2,2), (2,2)],  # padding mode\n",
    "                               (1,1),  # lhs/image dilation\n",
    "                               (1,1),  # rhs/kernel dilation\n",
    "                               dn)     # dimension_numbers\n",
    "\n",
    "print(f\"Output shape: {out.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd350d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "(20 + 10 - 5 - 4) * 3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0083efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, the direct convolution\n",
    "\n",
    "in_chan = 256  # number of input channels\n",
    "out_chan = 64  # number of output channels\n",
    "batch_size = 32\n",
    "kernel = jnp.ones((in_chan, out_chan, 5, 5))\n",
    "images = jnp.ones((batch_size, in_chan, 64, 64))\n",
    "\n",
    "dn = lax.conv_dimension_numbers(images.shape,  # Dimensions for the input\n",
    "                                kernel.shape,  # Dimensions of the kernel\n",
    "                                ('NCHW', 'IOHW', 'NCHW'))  # what each dimension is\n",
    "                                                 # in the input, kernel, and output\n",
    "\n",
    "out = lax.conv_general_dilated(images, # lhs = image tensor\n",
    "                               kernel, # rhs = conv kernel tensor\n",
    "                               (3,3),  # window strides\n",
    "                               [(2,2), (2,2)], # padding mode\n",
    "                               (1,1),  # lhs/image dilation\n",
    "                               (2,2),  # rhs/kernel dilation\n",
    "                               dn)     # dimension_numbers\n",
    "\n",
    "print(f\"Output shape: {out.shape}\")\n",
    "\n",
    "\n",
    "#help(jax.lax.conv_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef50e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, the corresponding transpose convolution\n",
    "images = jnp.ones((batch_size, in_chan, 20, 20))\n",
    "\n",
    "dn = lax.conv_dimension_numbers(images.shape,  # Dimensions for the input\n",
    "                                kernel.shape,  # Dimensions of the kernel\n",
    "                                ('NCHW', 'IOHW', 'NCHW'))  # what each dimension is\n",
    "                                                 # in the input, kernel, and output\n",
    "\n",
    "out = lax.conv_general_dilated(images, # lhs = image tensor\n",
    "                               kernel, # rhs = conv kernel tensor\n",
    "                               (1,1),  # window strides\n",
    "                               [(5,5), (5,5)],  # padding mode\n",
    "                               (3,3),  # lhs/image dilation\n",
    "                               (1,1),  # rhs/kernel dilation\n",
    "                               dn)     # dimension_numbers\n",
    "\n",
    "print(f\"Output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def padding(input_dim, output_dim, stride, kernel_size, dilation):\n",
    "    \"\"\"Calculate the padding for a convolution.\n",
    "\n",
    "    The padding is calculated to attain the desired input and output\n",
    "    dimensions.\n",
    "\n",
    "    :param input_dim: dimension of the (square) input\n",
    "    :type input_dim: int\n",
    "    :param output_dim: height or width of the square convolution output\n",
    "    :type output_dim: int\n",
    "    :param stride: stride\n",
    "    :type stride: int\n",
    "    :param kernel_size: kernel size\n",
    "    :type kernel_size: int\n",
    "    :param dilation: dilation\n",
    "    :type dilation: int\n",
    "    :returns: padding for the convolution, residual for the transpose convolution\n",
    "    :rtype: int, int\n",
    "    \"\"\"\n",
    "    pad = math.ceil(0.5 * (\n",
    "        stride * (output_dim - 1) - input_dim + dilation * (kernel_size - 1) + 1))\n",
    "    err_msg = \"kernel, stride, dilation and input/output sizes do not match\"\n",
    "    if pad >= 0:\n",
    "        r = (input_dim + 2 * pad - dilation * (kernel_size - 1) - 1) % stride\n",
    "        # verify that the padding is correct\n",
    "        assert ( output_dim ==\n",
    "            math.floor((input_dim + 2 * pad - dilation * (kernel_size - 1) - 1) / stride) + 1\n",
    "            ), err_msg\n",
    "        return pad, r\n",
    "    else:\n",
    "        raise ValueError(err_msg)\n",
    "    \n",
    "padding(20, 64, 1/3, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f19a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
