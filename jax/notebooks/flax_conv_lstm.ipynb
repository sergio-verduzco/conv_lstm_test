{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flax_conv_lstm.ipynb\n",
    "\n",
    "A convolutional LSTM that predicts the next image for the block manipulation task.  \n",
    "This version uses Flax's [ConvLSTMCell](https://flax.readthedocs.io/en/latest/_modules/flax/linen/recurrent.html#ConvLSTMCell) rather than `conv_general_dilated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z/projects/language_network/conv_lstm_test/jax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/environments/jax/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from flax_conv_lstm import *\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "# from jax import lax\n",
    "from jax import random\n",
    "from jax.tree_util import tree_map\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "# from torch.utils import data\n",
    "import torch\n",
    "# import math\n",
    "from functools import partial\n",
    "# from jax.tree_util import Partial\n",
    "from flax import linen as nn\n",
    "from flax.linen.recurrent import ConvLSTMCell\n",
    "import optax\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration dictionary:\n",
      "{'data_path': '/media/z/Data/datasets/language_network/groupA1_traindataset_256x256.h5', 'model_path': '/media/z/Data/datasets/language_network/saved_params.pkl', 'batch_size': 32, 'n_epochs': 500, 'learning_rate': 0.0005, 'h_channels': 12, 'inp_kernel_size': 3, 'hid_kernel_size': 3, 'trans_kernel_size': 5, 's': 2, 'p': 0, 'd': 1, 'kd': 1}\n"
     ]
    }
   ],
   "source": [
    "# configuration and data loader\n",
    "config = read_config('rnn_config.yaml')\n",
    "dataset = JaxDataset(config['data_path'])\n",
    "print(\"Configuration dictionary:\")\n",
    "print(config)\n",
    "data_loader = NumpyLoader(dataset, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision shape: (32, 50, 256, 256, 3). \t Vision type: <class 'numpy.ndarray'>\n",
      "Motor shape: (32, 50, 60). \t Motor type: <class 'numpy.ndarray'>\n",
      "Language shape: (32, 5, 20). \t Language type: <class 'numpy.ndarray'>.\n",
      "Mask shape: (32, 50). \t Mask type: <class 'numpy.ndarray'>.\n",
      "Lang_mask shape: (32, 5). \t Lang_mask type: <class 'numpy.ndarray'>.\n"
     ]
    }
   ],
   "source": [
    "# explore the data_loader object\n",
    "datum = next(data_loader._get_iterator())\n",
    "vision, motor, language, mask, lang_mask = datum\n",
    "print(f\"Vision shape: {vision.shape}. \\t Vision type: {type(vision)}\")\n",
    "print(f\"Motor shape: {motor.shape}. \\t Motor type: {type(motor)}\")\n",
    "print(f\"Language shape: {language.shape}. \\t Language type: {type(language)}.\")\n",
    "print(f\"Mask shape: {mask.shape}. \\t Mask type: {type(mask)}.\")\n",
    "print(f\"Lang_mask shape: {lang_mask.shape}. \\t Lang_mask type: {type(lang_mask)}.\")\n",
    "config['vision'] = vision[:, 0:1, :, :, :]  # for shape reference when creating parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "h_channels = config['h_channels']\n",
    "kernel_size = (config['hid_kernel_size'], config['hid_kernel_size'])\n",
    "strides = config['s']\n",
    "\n",
    "conv_lstm_cell = ConvLSTMCell(h_channels,\n",
    "                              kernel_size,\n",
    "                              strides=1)\n",
    "\n",
    "key = jax.random.key(23)\n",
    "key, *l1_keys = random.split(key, 4)\n",
    "inp_shape = vision[:, 0, :, :, :].shape\n",
    "carry = conv_lstm_cell.initialize_carry(l1_keys[0], inp_shape)\n",
    "carry = (0.05 * random.normal(random.key(1), carry[0].shape),  # non-zero initialization\n",
    "         0.05 * random.normal(random.key(2), carry[1].shape))\n",
    "\n",
    "conv_out, conv_params = conv_lstm_cell.init_with_output(l1_keys[1],\n",
    "                                                        carry, vision[:, 0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'hh': {'bias': Array(0., dtype=float32),\n",
       "   'kernel': Array(0.00212648, dtype=float32)},\n",
       "  'ih': {'bias': Array(0., dtype=float32),\n",
       "   'kernel': Array(0.01056828, dtype=float32)}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jax.tree_util.tree_map(jnp.shape, conv_out)\n",
    "jax.tree_util.tree_map(jnp.mean, conv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                              ConvLSTMCell Summary                              \u001b[0m\n",
      "┏━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams          \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│      │ ConvLSTMCell │ - -              │ - -              │                  │\n",
      "│      │              │ \u001b[2mfloat32\u001b[0m[32,256,… │ \u001b[2mfloat32\u001b[0m[32,256,… │                  │\n",
      "│      │              │   -              │   -              │                  │\n",
      "│      │              │ \u001b[2mfloat32\u001b[0m[32,256,… │ \u001b[2mfloat32\u001b[0m[32,256,… │                  │\n",
      "│      │              │ -                │ -                │                  │\n",
      "│      │              │ \u001b[2mfloat32\u001b[0m[32,256,… │ \u001b[2mfloat32\u001b[0m[32,256,… │                  │\n",
      "├──────┼──────────────┼──────────────────┼──────────────────┼──────────────────┤\n",
      "│ ih   │ Conv         │ \u001b[2mfloat32\u001b[0m[32,256,… │ \u001b[2mfloat32\u001b[0m[32,256,… │ bias:            │\n",
      "│      │              │                  │                  │ \u001b[2mfloat32\u001b[0m[48]      │\n",
      "│      │              │                  │                  │ kernel:          │\n",
      "│      │              │                  │                  │ \u001b[2mfloat32\u001b[0m[3,3,3,4… │\n",
      "│      │              │                  │                  │                  │\n",
      "│      │              │                  │                  │ \u001b[1m1,344 \u001b[0m\u001b[1;2m(5.4 KB)\u001b[0m   │\n",
      "├──────┼──────────────┼──────────────────┼──────────────────┼──────────────────┤\n",
      "│ hh   │ Conv         │ \u001b[2mfloat32\u001b[0m[32,256,… │ \u001b[2mfloat32\u001b[0m[32,256,… │ bias:            │\n",
      "│      │              │                  │                  │ \u001b[2mfloat32\u001b[0m[48]      │\n",
      "│      │              │                  │                  │ kernel:          │\n",
      "│      │              │                  │                  │ \u001b[2mfloat32\u001b[0m[3,3,12,… │\n",
      "│      │              │                  │                  │                  │\n",
      "│      │              │                  │                  │ \u001b[1m5,232 \u001b[0m\u001b[1;2m(20.9 KB)\u001b[0m  │\n",
      "├──────┼──────────────┼──────────────────┼──────────────────┼──────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m6,576 \u001b[0m\u001b[1;2m(26.3 KB)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\n",
      "└──────┴──────────────┴──────────────────┴──────────────────┴──────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                       Total Parameters: 6,576 \u001b[0m\u001b[1;2m(26.3 KB)\u001b[0m\u001b[1m                        \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conv_lstm_cell.tabulate(key, carry,\n",
    "                        vision[:, 0, :, :, :],\n",
    "                       compute_flops=False, compute_vjp_flops=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_trans = nn.ConvTranspose(3, config['trans_kernel_size'])\n",
    "trans_out, trans_params = conv_trans.init_with_output(l1_keys[2],\n",
    "                                                      jnp.ones(conv_out[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_step(params, carry, x):\n",
    "    new_carry, h = conv_lstm_cell.apply(params['conv_params'], carry, x)\n",
    "    new_x = conv_trans.apply(params['trans_params'], h)\n",
    "    return new_carry, x\n",
    "\n",
    "def prediction_n_steps(params, carry, vision):\n",
    "    n = vision.shape[1]\n",
    "    x_pred = jnp.zeros_like(vision)\n",
    "    x = vision[:, 0, :, :, :]\n",
    "    x_pred = x_pred.at[:, 0, :, :, :].set(x)\n",
    "    for i in range(1, n):\n",
    "        carry, x = prediction_step(params, carry, x)\n",
    "        x_pred = x_pred.at[:, i, :, :, :].set(x)\n",
    "    return x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50, 256, 256, 3)\n",
      "0.028330727\n"
     ]
    }
   ],
   "source": [
    "params = {'conv_params': conv_params,\n",
    "          'trans_params': trans_params}\n",
    "\n",
    "@jax.jit\n",
    "def mse(params, carry, vision):\n",
    "    x_pred = prediction_n_steps(params, carry, vision)\n",
    "    # print(f\"Mean x_pred: {jnp.mean(x_pred)}\")\n",
    "    return jnp.mean(optax.l2_loss(x_pred, vision))\n",
    "    # return jnp.mean((x_pred - vision)**2)\n",
    "\n",
    "x_pred = prediction_n_steps(params, carry, vision)\n",
    "print(x_pred.shape)\n",
    "print(mse(params, carry, vision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: 0.03069593571126461\n",
      "Loss at epoch 2: 0.026686973869800568\n",
      "Loss at epoch 4: 0.03228026628494263\n",
      "Loss at epoch 6: 0.031136872246861458\n",
      "Loss at epoch 8: 0.028465382754802704\n",
      "Loss at epoch 10: 0.028439421206712723\n",
      "Loss at epoch 12: 0.03022477589547634\n"
     ]
    }
   ],
   "source": [
    "tx = optax.adam(learning_rate=config['learning_rate'])\n",
    "opt_state = tx.init(params)\n",
    "loss_grad_fn = jax.value_and_grad(mse)\n",
    "\n",
    "start_time = time.time()\n",
    "warmup_epochs = 1\n",
    "\n",
    "for epoch in range(config['n_epochs']): #range(config['n_epochs']):\n",
    "    if epoch == warmup_epochs:\n",
    "        start_time = time.time()\n",
    "    for datum in data_loader:\n",
    "        vision, motor, language, mask, lang_mask = datum\n",
    "        loss_val, grads = loss_grad_fn(params, carry, vision)\n",
    "        # print(tree_map(jnp.mean, grads))\n",
    "        # print(f\"Loss: {loss_val}\")\n",
    "        updates, opt_state = tx.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"Loss at epoch {epoch}: {loss_val}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Completed {config['n_epochs'] - warmup_epochs} epochs in {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sgd_update(params, carry, vision, lr):\n",
    "    loss_val, grads = jax.value_and_grad(mse)(params, carry, vision)\n",
    "    new_params = tree_map(\n",
    "        lambda p, g: p - lr * g, params, grads\n",
    "    )\n",
    "    return loss_val, new_params\n",
    "\n",
    "lr = config['learning_rate']\n",
    "for epoch in range(config['n_epochs']):\n",
    "    for datum in data_loader:\n",
    "        vision, motor, language, mask, lang_mask = datum\n",
    "        loss_val, params = sgd_update(params, carry, vision, lr)\n",
    "    if epoch % 4 == 0:\n",
    "        print(f\"Epoch {epoch}, loss: {loss_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some predictions\n",
    "\n",
    "prediction = prediction_n_steps(params, carry, vision)\n",
    "prediction = prediction.transpose(0, 1, 4, 2, 3)\n",
    "\n",
    "pt_prediction = torch.from_numpy(np.asarray(prediction)) # don't use in real code\n",
    "example_index = 8\n",
    "vision_ex = pt_prediction[example_index, :, :, :, :]\n",
    "print(f\"For index {example_index}, the vision data has shape {vision_ex.shape}\")\n",
    "\n",
    "imgs = vision_ex / 2. + 0.5\n",
    "grid = make_grid(torch.tensor(imgs))\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, figsize=(10,10))\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5m 14s for 100 epochs without jit\n",
    "\n",
    "2m 52s for 100 epochs with jit (no warmup)  \n",
    "102m for 4000 epochs with jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
