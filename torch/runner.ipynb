{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858e3823-c2a9-4ce4-8617-a218466d98c3",
   "metadata": {},
   "source": [
    "# runner.ipynb\n",
    "\n",
    "A notebook to use the methods in `jax_conv_lstm.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5511417-6a3f-4f2a-b156-ede7d1d093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_conv_lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e83266a-561d-4de0-ba5a-17d5052c0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/z/Data/datasets/language_network/groupA1_traindataset_256x256.h5\"\n",
    "config = read_config('rnn_config.yaml')\n",
    "\n",
    "data_loader = TorchDataLoader(path, config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05eaa700-5b65-475a-9e96-1fbd853f1d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision shape: torch.Size([35, 50, 3, 256, 256]). \t Vision type: <class 'torch.Tensor'>\n",
      "Motor shape: torch.Size([35, 50, 60]). \t Motor type: <class 'torch.Tensor'>\n",
      "Language shape: torch.Size([35, 5, 20]). \t Language type: <class 'torch.Tensor'>.\n",
      "Mask shape: torch.Size([35, 50]). \t Mask type: <class 'torch.Tensor'>.\n",
      "Lang_mask shape: torch.Size([35, 5]). \t Lang_mask type: <class 'torch.Tensor'>.\n"
     ]
    }
   ],
   "source": [
    "datum = next(data_loader._get_iterator())\n",
    "vision, motor, language, mask, lang_mask = datum\n",
    "print(f\"Vision shape: {vision.shape}. \\t Vision type: {type(vision)}\")\n",
    "print(f\"Motor shape: {motor.shape}. \\t Motor type: {type(motor)}\")\n",
    "print(f\"Language shape: {language.shape}. \\t Language type: {type(language)}.\")\n",
    "print(f\"Mask shape: {mask.shape}. \\t Mask type: {type(mask)}.\")\n",
    "print(f\"Lang_mask shape: {lang_mask.shape}. \\t Lang_mask type: {type(lang_mask)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ad3755-b1d6-4e91-af50-9614565c9c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_loader.dataset.motor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "996bb02d-e7fa-4573-8e50-b9a6cf66c009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h shape: torch.Size([35, 12, 128, 128])\n",
      "c shape: torch.Size([35, 12, 128, 128])\n",
      "inp_convs: torch.Size([35, 48, 128, 128])\n",
      "hid_convs: torch.Size([35, 48, 128, 128])\n",
      "ic: torch.Size([35, 12, 128, 128])\n",
      "h shape: torch.Size([35, 12, 128, 128])\n",
      "c shape: torch.Size([35, 12, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# test conv_lstm cell\n",
    "inp_channels = 3\n",
    "hid_size = 128  # desired hidden state size\n",
    "pad = padding(vision.shape[3],\n",
    "              hid_size,\n",
    "              config['s'],\n",
    "              config['inp_kernel_size'],\n",
    "              config['kd'])\n",
    "\n",
    "conv_lstm = ConvLSTMCell(inp_channels,\n",
    "                         config['h_channels'],\n",
    "                         config['inp_kernel_size'],\n",
    "                         config['hid_kernel_size'],\n",
    "                         inp_stride=config['s'],\n",
    "                         inp_padding=pad,\n",
    "                         ik_dilation=config['kd'])\n",
    "\n",
    "image_batch = vision[:, 0, :, :, :].to(torch.float32)\n",
    "\n",
    "h, c = conv_lstm.init_hidden_from_normal(vision.shape[0], (hid_size, hid_size))\n",
    "\n",
    "print(f\"h shape: {h.shape}\")\n",
    "print(f\"c shape: {c.shape}\")\n",
    "\n",
    "h, c = conv_lstm(image_batch, (h, c))\n",
    "\n",
    "print(f\"h shape: {h.shape}\")\n",
    "print(f\"c shape: {c.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d4f177-4bcf-4520-8586-5dfe16a1e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f080b-f7ff-443f-986c-4eac9346dc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
